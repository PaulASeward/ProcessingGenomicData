{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install biopython"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcFLWe8FV0yr",
        "outputId": "703ab54b-acca-4aa8-cf93-e1fecf46a2f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: biopython in /usr/local/lib/python3.9/dist-packages (1.81)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from biopython) (1.22.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KcUwqEERUx32"
      },
      "outputs": [],
      "source": [
        "from Bio import SeqIO\n",
        "from Bio.Seq import Seq\n",
        "from Bio.SeqRecord import SeqRecord\n",
        "import os\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def cgr(seq, order, k):\n",
        "    \"\"\"\n",
        "    Creates a two-dimensional numerical representations of the genomic\n",
        "    sequences using the Chaos Game Representation (CGR)\n",
        "    :param seq: The String genomic sequence\n",
        "    :param order: Default order=\"ACGT\"\n",
        "    :param k: Represents the frequencies of all possible sub-words of length 7\n",
        "    constructed over the alphabet set {A, C, G, T}.\n",
        "    :return: 2D plot of CGR\n",
        "    \"\"\"\n",
        "    ln = len(seq)\n",
        "    pw = 2**k\n",
        "    out = [[0 for i in range(pw)] for j in range(pw)]\n",
        "    x = 2**(k-1)\n",
        "    y = 2**(k-1)\n",
        "\n",
        "    for i in range(0,ln):\n",
        "        x=x//2\n",
        "        y=y//2\n",
        "        if(seq[i] == order[2] or seq[i] == order[3]):\n",
        "            x = x + (2**(k-1))\n",
        "        if(seq[i] == order[0] or seq[i] == order[3]):\n",
        "            y = y + (2**(k-1))\n",
        "        if(i>=k-1):\n",
        "            out[y][x] = out[y][x]+1\n",
        "    return out"
      ],
      "metadata": {
        "id": "x4IlEDBTVGV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_cgr_sequences(path):\n",
        "    \"\"\"\n",
        "    Reads in every fasta file from directory path paramater. Cleans string then passes it to helper cgr function.\n",
        "    :param path: The path to read individual fasta files from.\n",
        "    :return: A list of cgr plots representing each fasta file from original directory\n",
        "    \"\"\"\n",
        "    proper_letters = [\"A\", \"C\", \"G\", \"T\"]\n",
        "    os.chdir(path)\n",
        "    cgr_list_sequences = []\n",
        "    for file in os.listdir():\n",
        "        if file.endswith(\".fasta\"):\n",
        "            file_path = f\"{path}/{file}\"\n",
        "            fasta = SeqIO.read(file_path, \"fasta\")  # Exception handling occurs in SeqIO.read method\n",
        "            fasta.upper()\n",
        "\n",
        "            # Ensure only the letters, A, C, G, T are in sequences\n",
        "            string_seq = str(fasta.seq)\n",
        "            for letter in string_seq:\n",
        "                if letter not in proper_letters:\n",
        "                    string_seq = string_seq.replace(letter, '')\n",
        "\n",
        "            # Write this altered sequence back into a SeqRecord object then into separate files\n",
        "            cgr_seq = cgr(string_seq, \"ACGT\", 7)\n",
        "\n",
        "            cgr_list_sequences.append(cgr_seq)\n",
        "    return cgr_list_sequences\n"
      ],
      "metadata": {
        "id": "WhEpTS3uWFjG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "\n",
        "# Update paths to  include Training and Testing Dataset directories\n",
        "# cwd = os.getcwd()\n",
        "cwd = \"/content/drive/MyDrive/Colab Notebooks/Asn2DataSet/\"\n",
        "training_data_path = os.path.join(cwd, \"TrainingDataset\")\n",
        "testing_input = os.path.join(cwd, \"TestingDataset\")\n",
        "\n",
        "\n",
        "\n",
        "# Create paths to variant inside TrainingDataset\n",
        "alpha_input = os.path.join(training_data_path, \"Alpha\")\n",
        "beta_input = os.path.join(training_data_path, \"Beta\")\n",
        "delta_input = os.path.join(training_data_path, \"Delta\")\n",
        "gamma_input = os.path.join(training_data_path, \"Gamma\")"
      ],
      "metadata": {
        "id": "D-aEZ_9miM8a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Declare target variable to predict\n",
        "target_variable = []\n",
        "\n",
        "# Run each Fasta file through function to clean string then create cgr plot\n",
        "# Concatenate the 2d plot into a 1d vector and append the variant to target variable list\n",
        "alpha_sequences = create_cgr_sequences(alpha_input)\n",
        "for i in range(len(alpha_sequences)):\n",
        "    alpha_sequences[i] = np.array(alpha_sequences[i]).flatten()\n",
        "    target_variable.append(\"Alpha\")\n",
        "\n",
        "beta_sequences = create_cgr_sequences(beta_input)\n",
        "for i in range(len(beta_sequences)):\n",
        "    beta_sequences[i] = np.array(beta_sequences[i]).flatten()\n",
        "    target_variable.append(\"Beta\")\n",
        "\n",
        "delta_sequences = create_cgr_sequences(delta_input)\n",
        "for i in range(len(delta_sequences)):\n",
        "    delta_sequences[i] = np.array(delta_sequences[i]).flatten()\n",
        "    target_variable.append(\"Delta\")\n",
        "\n",
        "gamma_sequences = create_cgr_sequences(gamma_input)\n",
        "for i in range(len(gamma_sequences)):\n",
        "    gamma_sequences[i] = np.array(gamma_sequences[i]).flatten()\n",
        "    target_variable.append(\"Gamma\")\n",
        "\n",
        "\n",
        "# Do the same for testing input without labelling\n",
        "testing_sequences = create_cgr_sequences(testing_input)\n",
        "for i in range(len(testing_sequences)):\n",
        "    testing_sequences[i] = np.array(testing_sequences[i]).flatten()"
      ],
      "metadata": {
        "id": "jX-f8bc4iT0Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine all sequences into one dataframe\n",
        "all_sequences = alpha_sequences + beta_sequences + delta_sequences + gamma_sequences\n",
        "X = pd.DataFrame(all_sequences)\n",
        "X_test = pd.DataFrame(testing_sequences)\n",
        "# y = pd.DataFrame(target_variable)\n",
        "y = np.ravel(pd.DataFrame(target_variable)) \n",
        "\n",
        "\n",
        "# Normalize the features to by dividing each value by the range ensuring the values fall between 0 and 1.\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Ensure length of dataframes match number of input fasta files\n",
        "print(len(X_scaled)) \n",
        "print(len(y))"
      ],
      "metadata": {
        "id": "BSL_322GCHy4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecf7aabe-92bd-4152-ffb5-b5eb570c76e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2000\n",
            "2000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_scaled[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVkHXoYVrp7g",
        "outputId": "84062504-51e5-4167-cd73-019049ecceff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.         0.         0.         ... 0.5        0.         0.28571429]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Apply KNN classifier using 10-fold cross validation\n",
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "scores = cross_val_score(knn, X_scaled, y, cv=10, scoring='accuracy')\n",
        "mean_accuracy = np.mean(scores)\n",
        "print(\"Scores: \")\n",
        "print(scores)\n",
        "print(\"Mean accuracy:\", mean_accuracy)\n",
        "\n",
        "\n",
        "# Predict and predict the labels for the testing set\n",
        "knn.fit(X_scaled, y)\n",
        "y_pred = knn.predict(X_test_scaled)\n",
        "print(\"Predicted labels:\", y_pred)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSj_vPQJiYm3",
        "outputId": "2a436502-c39e-430a-a463-1fd544034ceb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scores: \n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "Mean accuracy: 1.0\n",
            "Predicted labels: ['Gamma' 'Gamma' 'Delta' 'Gamma' 'Gamma' 'Delta' 'Beta' 'Beta' 'Delta'\n",
            " 'Delta']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "\n",
        "# 10-fold cross-validation with logistic regression\n",
        "logreg = LogisticRegression(solver='liblinear', multi_class='ovr')\n",
        "score = cross_val_score(logreg, X_scaled, y, cv=10, scoring='accuracy')\n",
        "mean_accuracy = np.mean(scores)\n",
        "print(\"Scores: \")\n",
        "print(scores)\n",
        "print(\"Mean accuracy:\", mean_accuracy)\n",
        "\n",
        "\n",
        "# Predict the labels for the testing set\n",
        "logreg.fit(X_scaled, y)\n",
        "y_pred = logreg.predict(X_test_scaled)\n",
        "print(\"Predicted labels:\", y_pred)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "METiLFVVCH5R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01646edd-9fb7-4a1c-e597-80c05b9ba2e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scores: \n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "Mean accuracy: 1.0\n",
            "Predicted labels: ['Gamma' 'Gamma' 'Delta' 'Gamma' 'Gamma' 'Delta' 'Beta' 'Beta' 'Delta'\n",
            " 'Delta']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "dtc = DecisionTreeClassifier(random_state=5)\n",
        "scores = cross_val_score(dtc, X_scaled, y, cv=10, scoring='accuracy')\n",
        "mean_accuracy = np.mean(scores)\n",
        "\n",
        "print(\"Scores: \")\n",
        "print(scores)\n",
        "print(\"Mean accuracy:\", mean_accuracy)\n",
        "\n",
        "# Train the model on the full dataset\n",
        "dtc.fit(X_scaled, y)\n",
        "y_pred = dtc.predict(X_test_scaled)\n",
        "print(\"Predicted labels:\", y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBthzlV0tjKU",
        "outputId": "a9916507-1c86-4348-bb74-cb296508d7f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scores: \n",
            "[1.    1.    0.995 1.    1.    1.    1.    1.    0.995 0.995]\n",
            "Mean accuracy: 0.9984999999999999\n",
            "Predicted labels: ['Gamma' 'Gamma' 'Delta' 'Gamma' 'Gamma' 'Delta' 'Beta' 'Beta' 'Delta'\n",
            " 'Delta']\n"
          ]
        }
      ]
    }
  ]
}